{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391d1d51",
   "metadata": {},
   "source": [
    "# Changelogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0fb3c",
   "metadata": {},
   "source": [
    "| Version  | Loss | EM Score | F1 Score | Changes | Comment |\n",
    "|----------|----------|----------|--------------|---------|---------|\n",
    "|  |  |  |    |   |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4ec26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/ubuntu/kobigbird_final'\n",
    "Bigbird_workspace = '/KoBigBird'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaec1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/kobigbird_final\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c370e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoBigBird'...\n",
      "remote: Enumerating objects: 115, done.\u001b[K\n",
      "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
      "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
      "remote: Total 115 (delta 29), reused 101 (delta 20), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (115/115), 382.21 KiB | 11.94 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n",
      "/home/ubuntu/kobigbird_final/KoBigBird\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (5/5), 788 bytes | 788.00 KiB/s, done.\n",
      "From https://github.com/katie0809/KoBigBird\n",
      "   a5935cf..2f3348e  master     -> origin/master\n",
      "Updating a5935cf..2f3348e\n",
      "Fast-forward\n",
      " finetune/data/cls.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/katie0809/KoBigBird.git\n",
    "%cd $PATH$Bigbird_workspace\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dce3939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up to date with 'origin/master'.\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\t\u001b[31mKoBigBird/\u001b[m\r\n",
      "\r\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8113d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d274c6",
   "metadata": {},
   "source": [
    "# Load & Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.11.3\n",
    "!pip install sentencepiece\n",
    "!pip install -qr $PATH$Bigbird_workspace'/finetune/requirements.txt'\n",
    "# !pip install torch==1.8.1\n",
    "# !pip install git+https://github.com/vasudevgupta7/transformers.git@add_big_bird # TODO: replace with new pip version eventually\n",
    "# !sudo apt-get install liblzma-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d21cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 00:20:09.324746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import datetime\n",
    "import sys\n",
    "import hashlib\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchtext\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer,AdamWeightDecay,TFRobertaModel,TFBertModel,BertConfig\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "# ignore warnings filter\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')\n",
    "\n",
    "global bert_inputs, docs, qnas\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31714b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "1.18.5\n",
      "1.3.4\n",
      "2.4.0\n",
      "0.24.1\n",
      "4.11.3\n",
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(keras.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(transformers.__version__)\n",
    "# print(pororo.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68a41e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11월 16일 0시 20분 실행'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"monologg/kobigbird-bert-base\"\n",
    "\n",
    "data_dir = PATH+'/output'\n",
    "train_file = data_dir + '/train.csv'\n",
    "test_file = data_dir + '/test.csv'\n",
    "samplesub_file = data_dir + '/sample_submission.csv'\n",
    "\n",
    "build_dir = PATH+'/build'\n",
    "# output_dir = build_dir / model_name\n",
    "# trn_encoded_file = output_dir / 'trn.enc.joblib'\n",
    "# val_predict_file = output_dir / f'{model_name}.val.txt'\n",
    "submission_file = 'sub.csv'\n",
    "\n",
    "id_col = 'id'\n",
    "text_col = 'excerpt'\n",
    "target_col = 'target'\n",
    "\n",
    "max_len = 1024\n",
    "ans_max = 200 # 답변 최대 글자수는 200\n",
    "epochs = 1\n",
    "n_fold = 5\n",
    "n_est = 9\n",
    "n_stop = 2\n",
    "batch_size = 8\n",
    "seed = 42\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "year, month, day, hour, min = now.year, now.month, now.day, now.hour, now.minute\n",
    "display(f'{month}월 {day}일 {hour}시 {min}분 실행')\n",
    "\n",
    "version = f'{day}{hour}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff49396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c7ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0474db7b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-16 00:24:14.782290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "11/16/2021 00:24:16 - ERROR - __main__ -   Failed to import XLA. No module named 'torch_xla'\n",
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'bert.pooler.bias', 'bert.pooler.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['qa_classifier.output.dense.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.qa_outputs.bias', 'qa_classifier.output.dense.weight', 'qa_classifier.intermediate.dense.bias', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.qa_outputs.weight', 'qa_classifier.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "11/16/2021 00:24:21 - INFO - __main__ -   configuration: Namespace(adam_epsilon=1e-08, all_korquad_2_sample=False, cache_dir='cache', data_dir='/home/ubuntu/kobigbird_final', dataset='korquad_2', do_eval=False, do_eval_during_train=False, do_lower_case=False, do_train=True, doc_stride=512, eval_batch_size=16, gradient_accumulation_steps=4, learning_rate=3e-05, max_answer_length=4096, max_grad_norm=1.0, max_query_length=64, max_seq_length=4096, model_name_or_path='monologg/kobigbird-bert-base', n_best_size=20, null_score_diff_threshold=0.0, num_train_epochs=1, output_dir='/home/ubuntu/kobigbird_final/output', predict_file='x_valid1_.csv', seed=42, task='qa', threads=4, train_batch_size=1, train_file='x_train1_.csv', use_tpu=False, version_2_with_negative=False, warmup_proportion=0.0, weight_decay=2e-05)\n",
      "11/16/2021 00:24:21 - INFO - __main__ -   1 GPU device detected\n",
      "132987it [01:31, 1452.98it/s]\n",
      "convert squad examples to features:   4%| | 5313/132987 [00:53<19:26, 109.46it/s"
     ]
    }
   ],
   "source": [
    "!python $PATH$Bigbird_workspace'/finetune/run.py' \\\n",
    "--task 'qa' \\\n",
    "--dataset 'korquad_2' \\\n",
    "--do_train \\\n",
    "--data_dir $PATH \\\n",
    "--train_file 'x_train1_.csv' \\\n",
    "--predict_file 'x_valid1_.csv' \\\n",
    "--model_name_or_path 'monologg/kobigbird-bert-base' \\\n",
    "--output_dir $PATH'/output' \\\n",
    "--data_dir $PATH \\\n",
    "--learning_rate 3e-5 \\\n",
    "--weight_decay 2e-5 \\\n",
    "--num_train_epochs 1 \\\n",
    "--train_batch_size 1 \\\n",
    "--max_seq_length 4096 \\\n",
    "--doc_stride 512 \\\n",
    "--max_answer_length 4096 \\\n",
    "--gradient_accumulation_steps 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7696c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a87ff395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대학생들의 주관적 규범이 창업의도에 미치는 영향: 자기효능감의 매개효과와 안정지향성...</td>\n",
       "      <td>을 증가시켰으며, 자기효능감은 창업의도에 영향을 주는 것으로 나타나 주관적 규범이 ...</td>\n",
       "      <td>경력지향성을 형성시키는 것은 무엇인가?</td>\n",
       "      <td>자신의 재능, 욕구, 동기, 태도 및 가치관 등이 통합되어 형성된 직업 관련 이미지...</td>\n",
       "      <td>201</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>제품, 공정, 서비스 통합 설계를 지원하는 제품자료모델</td>\n",
       "      <td>높아짐에 따라, 재료 사용(제품 설계), 생산(공정), 그리고 고객 서비스(사용 ...</td>\n",
       "      <td>기업이 관심을 가지는 제품 수명주기는 무엇으로 구성되어 있는가?</td>\n",
       "      <td>제품 설계, 생산, 그리고 고객 서비스로 구성되어 있다</td>\n",
       "      <td>116</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>걸음마기 아동의 어머니를 대상으로 한 부모존경-자녀존중 부모교육 프로그램의 효과</td>\n",
       "      <td>stress;social and emotional behaviors; 본문 부모의 ...</td>\n",
       "      <td>어린 시기의 부모역할이 더욱 중요한 이유는?</td>\n",
       "      <td>생애 초기의 부모자녀 간 상호작용의 질은 인간발달의 기초를 형성하므로</td>\n",
       "      <td>190</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>파골세포 분화에서 토사자 물 추출물의 효과</td>\n",
       "      <td>be a promising drug for use against bone disor...</td>\n",
       "      <td>골의 유지는 어떻게 조절되는가?</td>\n",
       "      <td>파골세포가 오래된 골을 흡수하고 조골세포가 새로운 골을 꾸준하게 생산함으로써 조절된다</td>\n",
       "      <td>147</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>안면이식에 대한 최근 동향: 한국에서의 안면이식은 어떤 단계에 있는가?</td>\n",
       "      <td>년 현재까지 총 21건의 안면이식이 시행되었다. 특히, 2009년에 6건이 시행된 ...</td>\n",
       "      <td>안면이식을 시행하기 위해 실질적으로 필요한 의학 분야는 어떻게 나눌 수 있는가?</td>\n",
       "      <td>첫째, 미세수술을 통한 재건수술, 둘째, 면역억제제 치료와 관련된 이식 분야, 셋째...</td>\n",
       "      <td>98</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33241</th>\n",
       "      <td>유방암 환자와 배우자의 갈등해결방식과 부부친밀도 및 가족기능</td>\n",
       "      <td>밀감과 밀접한 관련성이 있는 것으로 간주된다(Lee &amp; Ok, 2002). 부부간의...</td>\n",
       "      <td>부부간의 친밀감이란 어떤 개념인가?</td>\n",
       "      <td>부부가 서로에게 느끼는 매우 가깝고도 공유되는 밀접함을 의미하며, 상호관계의 질을 ...</td>\n",
       "      <td>52</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33242</th>\n",
       "      <td>500 PS급 선박 SCR 반응기에서 디퓨저 각도와 면적비에 따른 유동균일도 수치해석</td>\n",
       "      <td>; 본문 디젤엔진은 주로 시간당, 마력당 비교적 낮은 소비율로 저급 연료를 사용할 ...</td>\n",
       "      <td>디젤엔진의 단점은?</td>\n",
       "      <td>질소산화물(NOx), 미세먼지 등은 디젤엔진이 가솔린엔진보다 최대 100배 이상 더...</td>\n",
       "      <td>299</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33243</th>\n",
       "      <td>정지 및 저속 하강 비행하는 헬리콥터 로터의 소음 해석 및 검증</td>\n",
       "      <td>로터 시스템에서는 복잡한 공력 특성이 나타나고 이로 인한 공력소음이 크게 발생하는 ...</td>\n",
       "      <td>회전익기의 소음 문제를 해결하기 위한 노력에는 어떤 것이 있는가?</td>\n",
       "      <td>블레이드 끝단의 형상을 변화시켜 블레이드-와류 간섭 소음을 저감시키는 등의 수동적인...</td>\n",
       "      <td>265</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33244</th>\n",
       "      <td>80년대 표준설계 초등학교 단위 교실의 환경친화적 리노베이션에 관한 연구</td>\n",
       "      <td>0s. 핵심 어휘 표준설계;환경친화;자연채광;자연환기;리노베이션; Standard ...</td>\n",
       "      <td>우리나라 초등학교 시설은 대부분 언제 지어졌는가?</td>\n",
       "      <td>1985년 이전 양적 팽창 시기</td>\n",
       "      <td>124</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33245</th>\n",
       "      <td>수학 문제해결 과정에 작용하는 메타정의의 사회역학적 기능</td>\n",
       "      <td>affect)는 정의적 측면의 가장 복합적이면서 중요한 요소로(Goldin, 200...</td>\n",
       "      <td>메타정의는 무엇을 설명해주는가?</td>\n",
       "      <td>마음(mind)이 정의를 어떻게 다루는지를 설명해준다</td>\n",
       "      <td>182</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33246 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      대학생들의 주관적 규범이 창업의도에 미치는 영향: 자기효능감의 매개효과와 안정지향성...   \n",
       "1                         제품, 공정, 서비스 통합 설계를 지원하는 제품자료모델   \n",
       "2           걸음마기 아동의 어머니를 대상으로 한 부모존경-자녀존중 부모교육 프로그램의 효과   \n",
       "3                                파골세포 분화에서 토사자 물 추출물의 효과   \n",
       "4                안면이식에 대한 최근 동향: 한국에서의 안면이식은 어떤 단계에 있는가?   \n",
       "...                                                  ...   \n",
       "33241                  유방암 환자와 배우자의 갈등해결방식과 부부친밀도 및 가족기능   \n",
       "33242    500 PS급 선박 SCR 반응기에서 디퓨저 각도와 면적비에 따른 유동균일도 수치해석   \n",
       "33243                정지 및 저속 하강 비행하는 헬리콥터 로터의 소음 해석 및 검증   \n",
       "33244           80년대 표준설계 초등학교 단위 교실의 환경친화적 리노베이션에 관한 연구   \n",
       "33245                    수학 문제해결 과정에 작용하는 메타정의의 사회역학적 기능   \n",
       "\n",
       "                                                    text  \\\n",
       "0      을 증가시켰으며, 자기효능감은 창업의도에 영향을 주는 것으로 나타나 주관적 규범이 ...   \n",
       "1       높아짐에 따라, 재료 사용(제품 설계), 생산(공정), 그리고 고객 서비스(사용 ...   \n",
       "2      stress;social and emotional behaviors; 본문 부모의 ...   \n",
       "3      be a promising drug for use against bone disor...   \n",
       "4      년 현재까지 총 21건의 안면이식이 시행되었다. 특히, 2009년에 6건이 시행된 ...   \n",
       "...                                                  ...   \n",
       "33241  밀감과 밀접한 관련성이 있는 것으로 간주된다(Lee & Ok, 2002). 부부간의...   \n",
       "33242  ; 본문 디젤엔진은 주로 시간당, 마력당 비교적 낮은 소비율로 저급 연료를 사용할 ...   \n",
       "33243  로터 시스템에서는 복잡한 공력 특성이 나타나고 이로 인한 공력소음이 크게 발생하는 ...   \n",
       "33244  0s. 핵심 어휘 표준설계;환경친화;자연채광;자연환기;리노베이션; Standard ...   \n",
       "33245  affect)는 정의적 측면의 가장 복합적이면서 중요한 요소로(Goldin, 200...   \n",
       "\n",
       "                                           question  \\\n",
       "0                             경력지향성을 형성시키는 것은 무엇인가?   \n",
       "1               기업이 관심을 가지는 제품 수명주기는 무엇으로 구성되어 있는가?   \n",
       "2                          어린 시기의 부모역할이 더욱 중요한 이유는?   \n",
       "3                                 골의 유지는 어떻게 조절되는가?   \n",
       "4      안면이식을 시행하기 위해 실질적으로 필요한 의학 분야는 어떻게 나눌 수 있는가?   \n",
       "...                                             ...   \n",
       "33241                           부부간의 친밀감이란 어떤 개념인가?   \n",
       "33242                                    디젤엔진의 단점은?   \n",
       "33243          회전익기의 소음 문제를 해결하기 위한 노력에는 어떤 것이 있는가?   \n",
       "33244                   우리나라 초등학교 시설은 대부분 언제 지어졌는가?   \n",
       "33245                             메타정의는 무엇을 설명해주는가?   \n",
       "\n",
       "                                                  answer  answer_start  \\\n",
       "0      자신의 재능, 욕구, 동기, 태도 및 가치관 등이 통합되어 형성된 직업 관련 이미지...           201   \n",
       "1                         제품 설계, 생산, 그리고 고객 서비스로 구성되어 있다           116   \n",
       "2                 생애 초기의 부모자녀 간 상호작용의 질은 인간발달의 기초를 형성하므로           190   \n",
       "3        파골세포가 오래된 골을 흡수하고 조골세포가 새로운 골을 꾸준하게 생산함으로써 조절된다           147   \n",
       "4      첫째, 미세수술을 통한 재건수술, 둘째, 면역억제제 치료와 관련된 이식 분야, 셋째...            98   \n",
       "...                                                  ...           ...   \n",
       "33241  부부가 서로에게 느끼는 매우 가깝고도 공유되는 밀접함을 의미하며, 상호관계의 질을 ...            52   \n",
       "33242  질소산화물(NOx), 미세먼지 등은 디젤엔진이 가솔린엔진보다 최대 100배 이상 더...           299   \n",
       "33243  블레이드 끝단의 형상을 변화시켜 블레이드-와류 간섭 소음을 저감시키는 등의 수동적인...           265   \n",
       "33244                                  1985년 이전 양적 팽창 시기           124   \n",
       "33245                      마음(mind)이 정의를 어떻게 다루는지를 설명해준다           182   \n",
       "\n",
       "       answer_end  \n",
       "0             280  \n",
       "1             146  \n",
       "2             228  \n",
       "3             194  \n",
       "4             176  \n",
       "...           ...  \n",
       "33241         105  \n",
       "33242         369  \n",
       "33243         414  \n",
       "33244         141  \n",
       "33245         211  \n",
       "\n",
       "[33246 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid2 = pd.read_csv('x_valid1_.csv')\n",
    "valid2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd4cb4",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "554af1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig\n",
    "from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            'monologg/kobigbird-bert-base', \n",
    "        )\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "            '/home/ubuntu/2021AiHub-ODQA/models/korquad_2/0-0-ckpt', \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a316bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\n",
    "    '주차장에서 한 여성이 피투성이가 된 채 발견된다. 피해자는 니콜 매닝. 놀랍게는 니콜은 임산부였고 누군가에게 폭행당한 후 제왕절개술로 아이를 뺏긴 채 쓰러져 있었다. 니콜에게 원한이 있는 사람을 중심으로 수사하던 성범죄 전담반은 니콜이 간호사로 일한 메타딘 클리닉의 환자였던 카일 노바첵과 니콜에게 부정 행위를 들켜 실직된 전직 간호사 에린 두 사람을 의심한다. 하지만 카일은 완벽한 알리바이를 제공하고 뭔가를 숨기는 듯한 에린 역시 더 이상 수사에 도움이 되지는 않는다. ',\n",
    "    \"The Ever Given is 400m-long (1,312ft) and weighs 200,000 tonnes, with a maximum capacity of 20,000 containers. It is currently carrying 18,300 containers.\"\n",
    "]\n",
    "q = [\n",
    "    '피해자의 이름은 무엇인가?',\n",
    "    \"How heavy is Ever Given?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3590cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "{'input_ids': tensor([[    2, 13070,  4771,  4828, 31318,  9356,  4770,  4898,  8657,  4741,\n",
      "          6907,  7721,  7605,  4584,  7136,  4604,  3246,  4696,  2935,  4662,\n",
      "          4649,   535,     3, 10730,  5045,  4293,  9954,  5189, 12853, 13555,\n",
      "          5189,  4521,  3573,  4741,  9356,  4770,  4898,  4839, 15032,  4584,\n",
      "          4322,  5246,  2935, 12853, 15032,  4598,  4584,  7131,  4681,  4990,\n",
      "         19137,  4618,  9888,  5189,  4521,  3573,  4839,  3913, 13070,  4771,\n",
      "          4828,  2776,  4584,  7954,  5547,  7581,  3738,  4742,   518,  7010,\n",
      "          4837, 13070,  4771,  4828, 31318,  4561,  9356,  4770,  4898,  8657,\n",
      "          4741, 10730,  5189,  4741,  9356,  4770,  4898,  4561,  8011,   516,\n",
      "          9356,  4770,  4898,  4561, 13181,   516, 15032,  4561,  8570, 24158,\n",
      "          4809,  8011,  4676,  2556,  4839,  9356,  4770,  4898,  4676, 15032,\n",
      "          4542,  4602,   516,  9231,  4561,  9356,  4770,  4898,  8657,  5222,\n",
      "          4676, 17839,  5284,  2968,  9231,  4542,  4602,   516, 24074,  4615,\n",
      "          4917,  4756, 14299, 12339,  2968,  7721,  9725,  4584,  7136,  4604,\n",
      "          3246,  4696,  6802,   518, 13070,  4771,  4828,  4544,  7713,  6936,\n",
      "         21864,  4584,  7320,  5189,  4741,  2579,  4604,  7299,  4647,  2989,\n",
      "          7320,  4837, 15032,  4676,  9231,  4561,  9356,  4712,  4630,  4741,\n",
      "         13070,  4771,  4828,  4604,  6946,  4681, 18150,  7360,  6934,  4837,\n",
      "          7955,  4771,  2937,  3468,  3738,  4742,   518,  9231,  4808,  4836,\n",
      "          9356,  4770,  4898,  4561, 13181,  6916,  8502,  4592,  4561, 13181,\n",
      "          4771,  2829,  4604,  6822, 13070,  4771,  4828,  4604,  6945,  4647,\n",
      "          3468,  3738,  4741,  7920, 19153,  6793,  4644,  4584,  6800,  6810,\n",
      "         15386,  7164,  5547,  3468,  3738,  4583,  6806, 32409,   518,  6886,\n",
      "         13070,  4771,  4828,  6890,  5045,  9982,  6870,  4644,  4839,  7713,\n",
      "         24074,  4666,  4864,  4598,  6946,  4756,  9356,  4770,  4898,  8657,\n",
      "          2968,  4584,  7382,  5189,  4674,  7773,  5189,  5070, 14919, 13070,\n",
      "          4771,  4828,  4604,  6981,  4647,  2989,  9504,  4809,  4627,  9231,\n",
      "          9356,  6847,  4602,  4584,  6800,  6870,  4741,  7127,  7773,  5045,\n",
      "          3242,  3614,  4742,   518,  7277,  3293,  6870, 31318,  4741, 13070,\n",
      "          4771,  4828,  4604,  6981,  4814,  4584,  3738,  4674,  4593, 15032,\n",
      "          4676,  9231,  4561,  9356,  9504,  4602,  4604,  6970, 10626,  9105,\n",
      "          7079,  4544,  7164,  4681,  4741, 13070,  4771,  4828,  4561,  7328,\n",
      "          4756,  6946,  4584,  7195,  4647,  3468,  3738, 21227,  9070,  4528,\n",
      "          6787,   518,  3293,  6870,  4561,  6918,  4741,  6936, 21864, 31318,\n",
      "          6941,  4837,  8510,  4809,  7038,  4874,  7085,  4647,  3468,  3738,\n",
      "          4741, 13070,  4771,  4828,  4561,  7320,  4602,  4604,  7564, 18150,\n",
      "          8431,  4647,  3468,  3738,  4604,  2579,  9627,  7093,  5045,  4742,\n",
      "           518, 13070,  4771,  4828,  8362,  4531,  4741, 16426,  5074,  4604,\n",
      "          6945, 10626,  8706,   520,   518,   524,   581,   516, 14754,   520,\n",
      "           518,   524,   581,   516,  7564,   520,   518,   528,   581,  4561,\n",
      "          8560,  4618,  7326, 10626,  6863,  4681,  4787,  4742,   518,  6910,\n",
      "         10331, 15531,  4561, 20646,  5162,  4676,  6921, 10331,  4561, 30446,\n",
      "          4590,  4552,  5162,  9627,  7052,  4681,  4787,  7022, 15032,  4666,\n",
      "          4722,  4906,  4521,  4874,  8366,  4641, 15032,  5162,  4676, 20646,\n",
      "          5162,  6899,  4584,   522, 11560,  4561, 15032, 30026,  5162,  4604,\n",
      "          7328,  4681,  4787,  4742,   518, 14930,  5222,  6842,  4561, 24074,\n",
      "          4771,  3839,  4598,  5189,  5070,  4604,  6822,  9792, 24074,  4874,\n",
      "          8755,  4568,  5397,  7325, 14908,  7280, 19137,  4618, 24074,  4874,\n",
      "         14930,  4568,  4701,  4583,  8366,  4641, 15032,  5162, 16991,  4584,\n",
      "          7848, 10331,  4561,  9086,  4625,  4874,  2554, 21227,  4222,  4787,\n",
      "          4742,   512,   552,  4714,  4612,  4508,   516,  7987,   531, 15420,\n",
      "          4598,   606, 18736,  4890,   516,  7785,   513,   518,  8362,  4531,\n",
      "          4561, 19137,  4584,  4741,  9888,  4531,  4874,  7328, 10626,  7124,\n",
      "          9725, 31318,  4756,  7026, 13070,  4771,  4828,  4584, 14930,  4837,\n",
      "         24074,  4771,  3766,  5055,  4840,  4662,  7797, 13562, 10730,  5547,\n",
      "          3468,  3738, 21227,  4222,  4787,  4742,   518,  8362,  4584,  6863,\n",
      "          4837, 20646,  4561, 26378,  4839,  6815,   517,  7237, 11560,  4544,\n",
      "          4990, 15032,  4839, 10912,   516,  3510,  4834,   516,  3771,  4590,\n",
      "          4561, 17004,  4544,  7389,  7715,   518,  8200,   516,  6910,   518,\n",
      "          8713,   516,  7033,   518, 11443,   509,  3731, 13334,  4590,  4874,\n",
      "           522, 11560, 31404,  3310,  4691,  4837,  4293,  6863,  4681,  4787,\n",
      "          4742,   518,  6863,  4837, 15032,  4561,  7284,  8570, 24158,  4809,\n",
      "          8011,  4839,  6889,  4561,   556, 17023,   521,  4676,  2556,  4742,\n",
      "           518,   556, 17023,   521,   518, 16033, 18222, 14655,  8576, 13050,\n",
      "          8712, 14655, 13050, 28424, 13838,  6908, 10456, 20864,  7918, 29900,\n",
      "          7726, 28817,  7949,  8162,  8151, 32244,  4515,   521,   513,  9066,\n",
      "          4612,   530,   539,  8177,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encodings = tokenizer(valid2['question'].iloc[10], \n",
    "                    valid2['text'].iloc[10], \n",
    "                    return_tensors=\"pt\")\n",
    "\n",
    "# input 을 cuda로 저장\n",
    "print(\"type \",type(encodings))\n",
    "print(encodings)\n",
    "\n",
    "# input_ids = encodings[\"input_ids\"].to(self.device).cpu()\n",
    "# token_type_ids = encodings[\"token_type_ids\"].to(self.device).cpu()\n",
    "# attention_mask = encodings[\"attention_mask\"].to(self.device).cpu()\n",
    "input_ids = encodings[\"input_ids\"]\n",
    "token_type_ids = encodings[\"token_type_ids\"]\n",
    "attention_mask = encodings[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1b64aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids=input_ids,token_type_ids=token_type_ids,attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "636e9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits, end_logits = outputs[0], outputs[1]\n",
    "token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
    "pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(encodings[\"input_ids\"][0][token_start_index: token_end_index + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3864314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa75c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
